{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a91bc3a4",
   "metadata": {},
   "source": [
    "**ФИО:** `Соломенцев А.С.`\n",
    "\n",
    "# Домашняя работа № 1\n",
    "\n",
    "**Цель:** обучить бинарный классификатор для поиска токсичного контента (твитов)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2cd2bbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "1f89f717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7778</th>\n",
       "      <td>ВОЖДЬ Я УБЬЮ ТЕБЯ СУКА\\n</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3342</th>\n",
       "      <td>Дык малолетний долбоёб поди и правда дебил как...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4119</th>\n",
       "      <td>этого пидора в Химках видал недавно на гик-кон...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5076</th>\n",
       "      <td>Демонетизация Это уже все давно поняли, что вы...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9264</th>\n",
       "      <td>Ну арендовать же конечно выгодней)\\n</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9042</th>\n",
       "      <td>Не бит не крашен, только летняя эксплуатация!\\n</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4830</th>\n",
       "      <td>Не тот пост, не тот коммент. Чувак, ты обдолба...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10793</th>\n",
       "      <td>Я был довольно болезненным, меня температура п...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2129</th>\n",
       "      <td>Кузьма куколд с больной уретрой, диабетом и ег...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2573</th>\n",
       "      <td>А в итоге соснут хохлы. Уж не знаю как, но это...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 comment  toxic\n",
       "7778                            ВОЖДЬ Я УБЬЮ ТЕБЯ СУКА\\n      1\n",
       "3342   Дык малолетний долбоёб поди и правда дебил как...      1\n",
       "4119   этого пидора в Химках видал недавно на гик-кон...      1\n",
       "5076   Демонетизация Это уже все давно поняли, что вы...      0\n",
       "9264                Ну арендовать же конечно выгодней)\\n      0\n",
       "9042     Не бит не крашен, только летняя эксплуатация!\\n      0\n",
       "4830   Не тот пост, не тот коммент. Чувак, ты обдолба...      1\n",
       "10793  Я был довольно болезненным, меня температура п...      0\n",
       "2129   Кузьма куколд с больной уретрой, диабетом и ег...      1\n",
       "2573   А в итоге соснут хохлы. Уж не знаю как, но это...      1"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/train_data.csv')\n",
    "df['toxic'] = df.toxic.astype(int)\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "304b0040",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.comment, df.toxic, test_size=0.2, stratify=df.toxic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "4ff0a038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([ 7302,  4293,  8209,  2074,  7974,  5644,  1087,  7498,  2561,\n",
       "             4653,\n",
       "            ...\n",
       "             7609,  9254,   347, 10172,  2780,  3467,  7888,  9949,  7625,\n",
       "             4601],\n",
       "           dtype='int64', length=8647)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "1a03cc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame(data=np.array([X_train, y_train]), index=['comment', 'toxic'], columns=X_train.index).T\n",
    "df_test = pd.DataFrame(data= np.array([X_test, y_test]), index= ['comment', 'toxic'], columns= X_test.index).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "16f19c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Baseline 4 - BoW для слов\n",
    "\n",
    "vec = CountVectorizer(ngram_range=(1,1))\n",
    "bow = vec.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "640338d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('меня', 20159),\n",
       " ('такая', 42072),\n",
       " ('кружка', 17895),\n",
       " ('процессе', 34309),\n",
       " ('мытья', 21402),\n",
       " ('развалилась', 35083),\n",
       " ('руках', 36954),\n",
       " ('на', 21463),\n",
       " ('100500', 28),\n",
       " ('мелких', 20083)]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(vec.vocabulary_.items())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "54358fde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.93      0.89      1440\n",
      "           1       0.82      0.68      0.75       722\n",
      "\n",
      "    accuracy                           0.85      2162\n",
      "   macro avg       0.84      0.80      0.82      2162\n",
      "weighted avg       0.84      0.85      0.84      2162\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=42, max_iter=1000)\n",
    "clf.fit(bow, y_train)\n",
    "y_pred = clf.predict(vec.transform(X_test))\n",
    "acc = accuracy_score(y_true=y_test, y_pred=y_pred)\n",
    "print(classification_report(y_true=y_test, y_pred=y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d82118",
   "metadata": {},
   "source": [
    "__________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ca105e",
   "metadata": {},
   "source": [
    "## baseline 2: preprocessing + bow -> 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d4582666",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from functools import lru_cache\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b8de1a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = MorphAnalyzer()\n",
    "regex = re.compile('[А-Яа-яA-z]+')\n",
    "\n",
    "def words_only(text, regex=regex):\n",
    "    try:\n",
    "        return regex.findall(text.lower())\n",
    "    except:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a54aacaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "@lru_cache(128)\n",
    "def lemmatize_word(token, pymorphy=m):\n",
    "    return pymorphy.parse(token)[0].normal_form\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    return [lemmatize_word(w) for w in text]\n",
    "\n",
    "mystopwords = stopwords.words('russian')\n",
    "def remove_stopwords(lemmas, stopwords= mystopwords):\n",
    "    return [w for w in lemmas if not w in stopwords and len(w) >= 3]\n",
    "\n",
    "def clean_text(text):\n",
    "    tokens = words_only(text)\n",
    "    lemmas = lemmatize_text(tokens)\n",
    "    \n",
    "    return ' '.join(remove_stopwords(lemmas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "a1b35b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 8647/8647 [00:32<00:00, 269.89it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>toxic</th>\n",
       "      <th>lemmas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1521</th>\n",
       "      <td>В любой семье не без урода, но тогда хотя бы б...</td>\n",
       "      <td>0</td>\n",
       "      <td>любой семья урод хотя бороться это кичиться со...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                comment toxic  \\\n",
       "1521  В любой семье не без урода, но тогда хотя бы б...     0   \n",
       "\n",
       "                                                 lemmas  \n",
       "1521  любой семья урод хотя бороться это кичиться со...  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "X_train_lem = list(tqdm(map(clean_text, X_train), total=len(X_train)))\n",
    "\n",
    "df_train['lemmas'] = X_train_lem\n",
    "\n",
    "df_train.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "d40d664c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 2162/2162 [00:08<00:00, 268.85it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>toxic</th>\n",
       "      <th>lemmas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2388</th>\n",
       "      <td>Я не знаю как это правильно сформулировать, но...</td>\n",
       "      <td>0</td>\n",
       "      <td>знать это правильно сформулировать женщина соц...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                comment toxic  \\\n",
       "2388  Я не знаю как это правильно сформулировать, но...     0   \n",
       "\n",
       "                                                 lemmas  \n",
       "2388  знать это правильно сформулировать женщина соц...  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_lem = list(tqdm(map(clean_text, X_test), total=len(X_test)))\n",
    "\n",
    "df_test['lemmas'] = X_test_lem\n",
    "\n",
    "df_test.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "1c0f46bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.95      0.90      1440\n",
      "           1       0.87      0.66      0.75       722\n",
      "\n",
      "    accuracy                           0.86      2162\n",
      "   macro avg       0.86      0.81      0.83      2162\n",
      "weighted avg       0.86      0.86      0.85      2162\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vec = CountVectorizer(ngram_range=(1,2))\n",
    "bow = vec.fit_transform(X_train_lem)\n",
    "\n",
    "clf = LogisticRegression(random_state=42, max_iter=500)\n",
    "clf.fit(bow, y_train)\n",
    "y_pred = clf.predict(vec.transform(X_test_lem))\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fadc70b",
   "metadata": {},
   "source": [
    "## baseline 3: preproc + fasttext -> 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "2a1e7211",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "cb5e567a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train.txt', 'w') as f:\n",
    "    for comment, toxic in zip(X_train_lem, y_train):\n",
    "        f.write(f'__label__{toxic} {comment.lower()}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "e01e503f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test.txt', 'w') as f:\n",
    "    for comment, toxic in zip(X_test_lem, y_test):\n",
    "        f.write(f'__label__{toxic} {comment.lower()}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "51ad85bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2162, 0.8672525439407955, 0.8672525439407955)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Read 0M words\n",
      "Number of words:  25090\n",
      "Number of labels: 2\n",
      "\r",
      "Progress: 100.0% words/sec/thread: 2494828 lr: -0.000002 avg.loss:  0.262966 ETA:   0h 0m 0s\r",
      "Progress: 100.0% words/sec/thread: 2488954 lr:  0.000000 avg.loss:  0.262966 ETA:   0h 0m 0s\n"
     ]
    }
   ],
   "source": [
    "classifier = fasttext.train_supervised('train.txt')\n",
    "result = classifier.test('test.txt')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "bd232fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8672525439407955\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.93      0.90      1440\n",
      "           1       0.85      0.73      0.79       722\n",
      "\n",
      "    accuracy                           0.87      2162\n",
      "   macro avg       0.86      0.83      0.85      2162\n",
      "weighted avg       0.87      0.87      0.86      2162\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = classifier.predict(X_test_lem)\n",
    "new_pred = [int(line[0][-1]) for line in pred[0]]\n",
    "acc = accuracy_score(y_test, new_pred)\n",
    "print(acc)\n",
    "print(classification_report(y_test, new_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "eeae37d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>toxic</th>\n",
       "      <th>lemmas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7302</th>\n",
       "      <td>У меня такая кружка в процессе мытья развалила...</td>\n",
       "      <td>0</td>\n",
       "      <td>кружка процесс мытьё развалиться рука мелкий о...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4293</th>\n",
       "      <td>отличная планировка, мастер бедрум и три спаль...</td>\n",
       "      <td>0</td>\n",
       "      <td>отличный планировка мастер бедрум спальня</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8209</th>\n",
       "      <td>А вот это вы ерунду говорите. Простому работяг...</td>\n",
       "      <td>0</td>\n",
       "      <td>это ерунда говорить простой работяга сладко см...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2074</th>\n",
       "      <td>Прибыль банка уменьшиться не за счёт начислены...</td>\n",
       "      <td>0</td>\n",
       "      <td>прибыль банк уменьшиться начислёный процент де...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7974</th>\n",
       "      <td>Все верно, но уровень гринда тут все равно нес...</td>\n",
       "      <td>0</td>\n",
       "      <td>всё верно уровень гринд всё равно несравнимый ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5644</th>\n",
       "      <td>а в Москве где не подскажете?)\\n</td>\n",
       "      <td>0</td>\n",
       "      <td>москва подсказать</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1087</th>\n",
       "      <td>Вкину свою хуиту, буду рад критике и подписчик...</td>\n",
       "      <td>1</td>\n",
       "      <td>вкинуть свой хуит рад критика подписчик</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7498</th>\n",
       "      <td>И флаг погранцовский висит, не настоящий погра...</td>\n",
       "      <td>1</td>\n",
       "      <td>флаг погранцовский висеть настоящий погранец д...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2561</th>\n",
       "      <td>Бля...что за название Тапок? Кто-нибудь может ...</td>\n",
       "      <td>1</td>\n",
       "      <td>бля название тапка нибыть мочь объяснить</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4653</th>\n",
       "      <td>бядь, я когда после отдыха на горах, возвращаю...</td>\n",
       "      <td>0</td>\n",
       "      <td>бесть отдых гора возвращаться город становитьс...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1788</th>\n",
       "      <td>Пусть лучше само евровидение стримит. Долбоеб ...</td>\n",
       "      <td>1</td>\n",
       "      <td>пусть хороший евровидение стримит долбоести чт...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3770</th>\n",
       "      <td>Тоже самое,в детстве ходил на атлетику и как-т...</td>\n",
       "      <td>0</td>\n",
       "      <td>самый детство ходить атлетика присниться переп...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8038</th>\n",
       "      <td>нету, ибо Иисус сказал.. - никто не приходит к...</td>\n",
       "      <td>0</td>\n",
       "      <td>нету ибо иисус сказать никто приходить бог оте...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4960</th>\n",
       "      <td>Как раз таки в Москве эти деньги можно получат...</td>\n",
       "      <td>0</td>\n",
       "      <td>таки москва деньга получать обычный восемь час...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2967</th>\n",
       "      <td>Мы живем во время настырного маркетинга и везд...</td>\n",
       "      <td>0</td>\n",
       "      <td>жить время настырный маркетинг вездесущий прод...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3418</th>\n",
       "      <td>Ты живёшь ради секса, долбоёб?\\n</td>\n",
       "      <td>1</td>\n",
       "      <td>живой ради секс долбо</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10603</th>\n",
       "      <td>имхо, ни чем лучше или хуже других. смертей не...</td>\n",
       "      <td>0</td>\n",
       "      <td>имхо хороший плохой смерть говорить вау выпили...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8918</th>\n",
       "      <td>В смысле мерзость? Что за угнетение? Мы не пид...</td>\n",
       "      <td>1</td>\n",
       "      <td>смысл мерзость угнетение пидоресс женщина иной...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5847</th>\n",
       "      <td>что за ноунейм ну постоянно надрачивая на хохл...</td>\n",
       "      <td>1</td>\n",
       "      <td>ноунейм постоянно надрачивать хохлокарлик слож...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9496</th>\n",
       "      <td>Я уже говорил тебе, что такое безумие? Gifx\\n</td>\n",
       "      <td>1</td>\n",
       "      <td>говорить безумие gifx</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 comment toxic  \\\n",
       "7302   У меня такая кружка в процессе мытья развалила...     0   \n",
       "4293   отличная планировка, мастер бедрум и три спаль...     0   \n",
       "8209   А вот это вы ерунду говорите. Простому работяг...     0   \n",
       "2074   Прибыль банка уменьшиться не за счёт начислены...     0   \n",
       "7974   Все верно, но уровень гринда тут все равно нес...     0   \n",
       "5644                    а в Москве где не подскажете?)\\n     0   \n",
       "1087   Вкину свою хуиту, буду рад критике и подписчик...     1   \n",
       "7498   И флаг погранцовский висит, не настоящий погра...     1   \n",
       "2561   Бля...что за название Тапок? Кто-нибудь может ...     1   \n",
       "4653   бядь, я когда после отдыха на горах, возвращаю...     0   \n",
       "1788   Пусть лучше само евровидение стримит. Долбоеб ...     1   \n",
       "3770   Тоже самое,в детстве ходил на атлетику и как-т...     0   \n",
       "8038   нету, ибо Иисус сказал.. - никто не приходит к...     0   \n",
       "4960   Как раз таки в Москве эти деньги можно получат...     0   \n",
       "2967   Мы живем во время настырного маркетинга и везд...     0   \n",
       "3418                    Ты живёшь ради секса, долбоёб?\\n     1   \n",
       "10603  имхо, ни чем лучше или хуже других. смертей не...     0   \n",
       "8918   В смысле мерзость? Что за угнетение? Мы не пид...     1   \n",
       "5847   что за ноунейм ну постоянно надрачивая на хохл...     1   \n",
       "9496       Я уже говорил тебе, что такое безумие? Gifx\\n     1   \n",
       "\n",
       "                                                  lemmas  \n",
       "7302   кружка процесс мытьё развалиться рука мелкий о...  \n",
       "4293           отличный планировка мастер бедрум спальня  \n",
       "8209   это ерунда говорить простой работяга сладко см...  \n",
       "2074   прибыль банк уменьшиться начислёный процент де...  \n",
       "7974   всё верно уровень гринд всё равно несравнимый ...  \n",
       "5644                                   москва подсказать  \n",
       "1087             вкинуть свой хуит рад критика подписчик  \n",
       "7498   флаг погранцовский висеть настоящий погранец д...  \n",
       "2561            бля название тапка нибыть мочь объяснить  \n",
       "4653   бесть отдых гора возвращаться город становитьс...  \n",
       "1788   пусть хороший евровидение стримит долбоести чт...  \n",
       "3770   самый детство ходить атлетика присниться переп...  \n",
       "8038   нету ибо иисус сказать никто приходить бог оте...  \n",
       "4960   таки москва деньга получать обычный восемь час...  \n",
       "2967   жить время настырный маркетинг вездесущий прод...  \n",
       "3418                               живой ради секс долбо  \n",
       "10603  имхо хороший плохой смерть говорить вау выпили...  \n",
       "8918   смысл мерзость угнетение пидоресс женщина иной...  \n",
       "5847   ноунейм постоянно надрачивать хохлокарлик слож...  \n",
       "9496                               говорить безумие gifx  "
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.iloc[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "80b1e2f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'И флаг погранцовский висит, не настоящий погранец давно бы уже чего-нибудь придумал.\\n'"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.loc[7498].comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fd82ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "\n",
    "# load tokenizer and model weights\n",
    "tokenizer = BertTokenizer.from_pretrained('SkolkovoInstitute/russian_toxicity_classifier')\n",
    "model = BertForSequenceClassification.from_pretrained('SkolkovoInstitute/russian_toxicity_classifier')\n",
    "\n",
    "# prepare the input\n",
    "batch = tokenizer.encode('ты супер', return_tensors='pt')\n",
    "\n",
    "# inference\n",
    "model(batch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
