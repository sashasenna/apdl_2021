{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0wTjLOlc8ib0"
   },
   "source": [
    "<h1><center>Простые векторные модели текста</center></h1>\n",
    "\n",
    "<img src=\"pipeline_vec.png\" alt=\"pipeline.png\" style=\"width: 400px;\"/>\n",
    "\n",
    "### Задача: классификация твитов по тональности\n",
    "\n",
    "В этом занятии мы познакомимся с распространенной задачей в анализе текстов: с классификацией текстов на классы.\n",
    "\n",
    "В рассмотренном тут примере классов будет два: положительный и отрицательный, такую постановку этой задачи обычно называют классификацией по тональности или sentiment analysis.\n",
    "\n",
    "Классификацию по тональности используют, например, в рекомендательных системах и при анализе отзывов клиентов, чтобы понять, понравилось ли людям кафе, кино, etc.\n",
    "\n",
    "Более подробно мы рассмотрим данную задачу и познакомимся с более сложными методами её решения в семинаре 3, а здесь разберем простые подходы, основанные на методе мешка слов.\n",
    "\n",
    "У нас есть [данные постов в твиттере](http://study.mokoron.com/), про из которых каждый указано, как он эмоционально окрашен: положительно или отрицательно. \n",
    "\n",
    "**Задача**: построить модель, которая по тексту поста предсказывает его эмоциональную окраску.\n",
    "\n",
    "\n",
    "Скачиваем данные: [положительные](https://drive.google.com/file/d/1mW_fUtYmRF19AXVySU0gJOIgx0-1EFgD/view?usp=sharing), [отрицательные](https://drive.google.com/file/d/1ZnsFuf-yfO3UEHlIpk7TTqfKkEMdm1EQ/view?usp=sharing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PuDVGp4O8ib1",
    "outputId": "11001569-4329-4c75-f8f0-2c5ec63708b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-05-11 22:14:42--  https://www.dropbox.com/s/fnpq3z4bcnoktiv/positive.csv?dl=0\n",
      "Распознаётся www.dropbox.com (www.dropbox.com)… 162.125.70.18\n",
      "Подключение к www.dropbox.com (www.dropbox.com)|162.125.70.18|:443... соединение установлено.\n",
      "HTTP-запрос отправлен. Ожидание ответа… 301 Moved Permanently\n",
      "Адрес: /s/raw/fnpq3z4bcnoktiv/positive.csv [переход]\n",
      "--2022-05-11 22:14:42--  https://www.dropbox.com/s/raw/fnpq3z4bcnoktiv/positive.csv\n",
      "Повторное использование соединения с www.dropbox.com:443.\n",
      "HTTP-запрос отправлен. Ожидание ответа… 302 Found\n",
      "Адрес: https://uc80ff7d37686dceff363a73ef02.dl.dropboxusercontent.com/cd/0/inline/BlEuuDZBt0E9rmKBHZcqooOIQScYnpNltLGQBoHD83VI9BO4ICLLVxUatcu0Fly232T4igosYZnQng88bdAWguWzJmlUp1q1gbQx9LD6nCc712GwAPQuO-RDBFXBrtiUgqs4kLUSNfcAeW2DFV7N8tb5TRGDkm7yDsCfiXPVubiS0A/file# [переход]\n",
      "--2022-05-11 22:14:43--  https://uc80ff7d37686dceff363a73ef02.dl.dropboxusercontent.com/cd/0/inline/BlEuuDZBt0E9rmKBHZcqooOIQScYnpNltLGQBoHD83VI9BO4ICLLVxUatcu0Fly232T4igosYZnQng88bdAWguWzJmlUp1q1gbQx9LD6nCc712GwAPQuO-RDBFXBrtiUgqs4kLUSNfcAeW2DFV7N8tb5TRGDkm7yDsCfiXPVubiS0A/file\n",
      "Распознаётся uc80ff7d37686dceff363a73ef02.dl.dropboxusercontent.com (uc80ff7d37686dceff363a73ef02.dl.dropboxusercontent.com)… 162.125.70.15\n",
      "Подключение к uc80ff7d37686dceff363a73ef02.dl.dropboxusercontent.com (uc80ff7d37686dceff363a73ef02.dl.dropboxusercontent.com)|162.125.70.15|:443... соединение установлено.\n",
      "HTTP-запрос отправлен. Ожидание ответа… 200 OK\n",
      "Длина: 26233379 (25M) [text/plain]\n",
      "Сохранение в: «positive.csv»\n",
      "\n",
      "positive.csv        100%[===================>]  25,02M  8,52MB/s    за 2,9s    \n",
      "\n",
      "2022-05-11 22:14:53 (8,52 MB/s) - «positive.csv» сохранён [26233379/26233379]\n",
      "\n",
      "--2022-05-11 22:14:53--  https://www.dropbox.com/s/r6u59ljhhjdg6j0/negative.csv?dl=0\n",
      "Распознаётся www.dropbox.com (www.dropbox.com)… 162.125.70.18\n",
      "Подключение к www.dropbox.com (www.dropbox.com)|162.125.70.18|:443... соединение установлено.\n",
      "HTTP-запрос отправлен. Ожидание ответа… 301 Moved Permanently\n",
      "Адрес: /s/raw/r6u59ljhhjdg6j0/negative.csv [переход]\n",
      "--2022-05-11 22:14:54--  https://www.dropbox.com/s/raw/r6u59ljhhjdg6j0/negative.csv\n",
      "Повторное использование соединения с www.dropbox.com:443.\n",
      "HTTP-запрос отправлен. Ожидание ответа… 302 Found\n",
      "Адрес: https://ucffdf2b53166891244a0c307a1a.dl.dropboxusercontent.com/cd/0/inline/BlFmjZ6-xH43guBXMs_A3jbszZYpVfNcn4GScqGXq3jrCuHe-8A59BZI2omnbQx5cFx6R9jy-O2zlg7WNpzssTROhg2UQvoZtErnswSn-GNqEtYsO1XpTslEuoNKD5sJDIBrzQeP1AYomzBJVt9mLGQETfFva2q6Pptkp4DcNem1cw/file# [переход]\n",
      "--2022-05-11 22:14:54--  https://ucffdf2b53166891244a0c307a1a.dl.dropboxusercontent.com/cd/0/inline/BlFmjZ6-xH43guBXMs_A3jbszZYpVfNcn4GScqGXq3jrCuHe-8A59BZI2omnbQx5cFx6R9jy-O2zlg7WNpzssTROhg2UQvoZtErnswSn-GNqEtYsO1XpTslEuoNKD5sJDIBrzQeP1AYomzBJVt9mLGQETfFva2q6Pptkp4DcNem1cw/file\n",
      "Распознаётся ucffdf2b53166891244a0c307a1a.dl.dropboxusercontent.com (ucffdf2b53166891244a0c307a1a.dl.dropboxusercontent.com)… 162.125.70.15\n",
      "Подключение к ucffdf2b53166891244a0c307a1a.dl.dropboxusercontent.com (ucffdf2b53166891244a0c307a1a.dl.dropboxusercontent.com)|162.125.70.15|:443... соединение установлено.\n",
      "HTTP-запрос отправлен. Ожидание ответа… 200 OK\n",
      "Длина: 24450101 (23M) [text/plain]\n",
      "Сохранение в: «negative.csv»\n",
      "\n",
      "negative.csv        100%[===================>]  23,32M  6,34MB/s    за 3,7s    \n",
      "\n",
      "2022-05-11 22:14:59 (6,34 MB/s) - «negative.csv» сохранён [24450101/24450101]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# если у вас линукс / мак / collab или ещё какая-то среда, в которой работает wget, можно так:\n",
    "# !wget --no-check-certificate 'https://www.dropbox.com/s/fnpq3z4bcnoktiv/positive.csv?dl=0' -O positive.csv\n",
    "# !wget --no-check-certificate 'https://www.dropbox.com/s/r6u59ljhhjdg6j0/negative.csv?dl=0' -O negative.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QPp8_2Sy8ib5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pd.set_option('display.max_columns', None)  \n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "pd.set_option('max_colwidth', 800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rsmSQOE98ib8"
   },
   "outputs": [],
   "source": [
    "positive = pd.read_csv('positive.csv', sep=';', usecols=[3], names=['text'])\n",
    "positive['label'] = ['positive'] * len(positive)\n",
    "negative = pd.read_csv('negative.csv', sep=';', usecols=[3], names=['text'])\n",
    "negative['label'] = ['negative'] * len(negative)\n",
    "df = pd.concat([positive, negative])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "znc9rKWk8ib-",
    "outputId": "ad6faf65-5361-434d-a46d-a7c176603a14"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>85940</th>\n",
       "      <td>Ресторан Прага, наконец то ужин!:) http://t.co/s75V746Uhv</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30750</th>\n",
       "      <td>Культурный шок: на самом попсовом радио города внезапно играет Placebo. :)</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56905</th>\n",
       "      <td>RT @VRSoloviev: Ни Фетисова,ни Роднину не пригласили на Олимпиаду( После скандала в прессе Фетисов получил аккредитацию.\\nКто за это отвечае…</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24835</th>\n",
       "      <td>@Star69Struk с почками же? У меня тож проблемы, оочень сильно боюсь оказаться в больнице ещё раз(</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83892</th>\n",
       "      <td>RT @Vlada188: @leonard_9901 ахуэть типирь (((0(0(</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                text     label\n",
       "85940                                                                                      Ресторан Прага, наконец то ужин!:) http://t.co/s75V746Uhv  positive\n",
       "30750                                                                     Культурный шок: на самом попсовом радио города внезапно играет Placebo. :)  positive\n",
       "56905  RT @VRSoloviev: Ни Фетисова,ни Роднину не пригласили на Олимпиаду( После скандала в прессе Фетисов получил аккредитацию.\\nКто за это отвечае…  negative\n",
       "24835                                              @Star69Struk с почками же? У меня тож проблемы, оочень сильно боюсь оказаться в больнице ещё раз(  negative\n",
       "83892                                                                                              RT @Vlada188: @leonard_9901 ахуэть типирь (((0(0(  negative"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Воспользуемся функцией для предобработки текста, которую мы написали в прошлом семинаре:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from functools import lru_cache\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "m = MorphAnalyzer()\n",
    "regex = re.compile(\"[А-Яа-яA-z]+\")\n",
    "\n",
    "def words_only(text, regex=regex):\n",
    "    try:\n",
    "        return regex.findall(text.lower())\n",
    "    except:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@lru_cache(maxsize=128)\n",
    "def lemmatize_word(token, pymorphy=m):\n",
    "    return pymorphy.parse(token)[0].normal_form\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    return [lemmatize_word(w) for w in text]\n",
    "\n",
    "\n",
    "mystopwords = stopwords.words('russian') \n",
    "def remove_stopwords(lemmas, stopwords = mystopwords):\n",
    "    return [w for w in lemmas if not w in stopwords and len(w) > 3]\n",
    "\n",
    "def clean_text(text):\n",
    "    tokens = words_only(text)\n",
    "    lemmas = lemmatize_text(tokens)\n",
    "    \n",
    "    return ' '.join(remove_stopwords(lemmas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████| 226834/226834 [05:26<00:00, 695.32it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>lemmas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>76226</th>\n",
       "      <td>Парни - это такие бесчувственные существа которые не понимают к сожалению эмоции других очень близких им людей. :-( Обидно!.....</td>\n",
       "      <td>negative</td>\n",
       "      <td>парень бесчувственный существо который понимать сожаление эмоция очень близкий человек обидно</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15433</th>\n",
       "      <td>@malova_o Поздравляю! А категорию потвердили? Я более-менее,погода очень плохая,сейчас+7,100% влажность и туман! Поэтому и голова болит!((</td>\n",
       "      <td>negative</td>\n",
       "      <td>malova_o поздравлять категория потвердить менее погода очень плохой влажность туман поэтому голова болеть</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58134</th>\n",
       "      <td>В нашей нормальности я перестала сомневаться уже давно))))) http://t.co/jXUVJoFo8g</td>\n",
       "      <td>positive</td>\n",
       "      <td>нормальность перестать сомневаться давно http jxuvjofo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63012</th>\n",
       "      <td>Хотела сделать коллаж дочери,херня какая-то получилась.\\nЯ открыточку пришлю кароч и всё о_О</td>\n",
       "      <td>negative</td>\n",
       "      <td>хотеть сделать коллаж дочь херня получиться открыточка прислать кароч</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22241</th>\n",
       "      <td>Мама спросила, что я хочу в подарок на НГ.Я в ступоре. У меня всё есть.А то, чего нет, мне никто не может дать( #жизньболь #нг #подарки</td>\n",
       "      <td>negative</td>\n",
       "      <td>мама спросить хотеть подарок ступор никто мочь дать жизньболь подарок</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                             text     label                                                                                                     lemmas\n",
       "76226            Парни - это такие бесчувственные существа которые не понимают к сожалению эмоции других очень близких им людей. :-( Обидно!.....  negative              парень бесчувственный существо который понимать сожаление эмоция очень близкий человек обидно\n",
       "15433  @malova_o Поздравляю! А категорию потвердили? Я более-менее,погода очень плохая,сейчас+7,100% влажность и туман! Поэтому и голова болит!((  negative  malova_o поздравлять категория потвердить менее погода очень плохой влажность туман поэтому голова болеть\n",
       "58134                                                          В нашей нормальности я перестала сомневаться уже давно))))) http://t.co/jXUVJoFo8g  positive                                                     нормальность перестать сомневаться давно http jxuvjofo\n",
       "63012                                                Хотела сделать коллаж дочери,херня какая-то получилась.\\nЯ открыточку пришлю кароч и всё о_О  negative                                      хотеть сделать коллаж дочь херня получиться открыточка прислать кароч\n",
       "22241     Мама спросила, что я хочу в подарок на НГ.Я в ступоре. У меня всё есть.А то, чего нет, мне никто не может дать( #жизньболь #нг #подарки  negative                                      мама спросить хотеть подарок ступор никто мочь дать жизньболь подарок"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from multiprocessing import Pool\n",
    "from tqdm import tqdm\n",
    "\n",
    "# with Pool(4) as p:\n",
    "lemmas = list(tqdm(map(clean_text, df['text']), total=len(df)))\n",
    "    \n",
    "df['lemmas'] = lemmas\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разбиваем на train и test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q3MD0bex8icC"
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df.lemmas, df.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8ppAtTFc8icE"
   },
   "source": [
    "## Мешок слов (Bag of Words, BoW)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4gJLFKQ38icE"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2AMGIJ8C8icH"
   },
   "source": [
    "... Но сперва пару слов об n-граммах. Что такое n-граммы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y0-y2A6k8icH"
   },
   "outputs": [],
   "source": [
    "from nltk import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d_lgEYzY8icJ",
    "outputId": "f9d482bd-0c45-4830-9e7b-1b49d1290468"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Если',), ('б',), ('мне',), ('платили',), ('каждый',), ('раз',)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = 'Если б мне платили каждый раз'.split()\n",
    "list(ngrams(sent, 1)) # униграммы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IDRi-68C8icM",
    "outputId": "8d04b779-f404-4c5e-e06c-125ef4f4572d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Если', 'б'),\n",
       " ('б', 'мне'),\n",
       " ('мне', 'платили'),\n",
       " ('платили', 'каждый'),\n",
       " ('каждый', 'раз')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ngrams(sent, 2)) # биграммы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jaUeKBDh8icO",
    "outputId": "831fbc23-1c08-4b7b-e5fd-856c10132bdc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Если', 'б', 'мне'),\n",
       " ('б', 'мне', 'платили'),\n",
       " ('мне', 'платили', 'каждый'),\n",
       " ('платили', 'каждый', 'раз')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ngrams(sent, 3)) # триграммы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z325_XfX8icS",
    "outputId": "5da7999f-0cf3-4964-8d23-e958f21d5f43"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Если', 'б', 'мне', 'платили', 'каждый'),\n",
       " ('б', 'мне', 'платили', 'каждый', 'раз')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ngrams(sent, 5)) # ... пентаграммы?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "80h0e8FJ8icV"
   },
   "source": [
    "Итак, мы хотим преобразовать наши обработанные данные в вектора с помощью мешка слов. Мешок слов можно строить как для отдельных слов (лемм в нашем случае), так и для n-грамм, и это может улучшать качество. \n",
    "\n",
    "Объект `CountVectorizer` делает простую вещь:\n",
    "* строит для каждого документа (каждой пришедшей ему строки) вектор размерности `n`, где `n` -- количество слов или n-грам во всём корпусе\n",
    "* заполняет каждый i-тый элемент количеством вхождений слова в данный документ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0SQaMJbl8icW"
   },
   "outputs": [],
   "source": [
    "vec = CountVectorizer(ngram_range=(1, 1)) # строим BoW для слов\n",
    "bow = vec.fit_transform(x_train) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g6eZOyAf8icY"
   },
   "source": [
    "ngram_range отвечает за то, какие n-граммы мы используем в качестве признаков:<br/>\n",
    "ngram_range=(1, 1) -- униграммы<br/>\n",
    "ngram_range=(3, 3) -- триграммы<br/>\n",
    "ngram_range=(1, 3) -- униграммы, биграммы и триграммы.\n",
    "\n",
    "В vec.vocabulary_ лежит словарь: соответствие слов и их индексов в словаре:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j8cncS9M8icY",
    "outputId": "c1943f5c-3400-4fb1-d218-c8f89d225634"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('atmosphaere', 8681),\n",
       " ('интересно', 115071),\n",
       " ('представлять', 142234),\n",
       " ('https', 31398),\n",
       " ('bwzxwin', 12850),\n",
       " ('знать', 113767),\n",
       " ('измениться', 114493),\n",
       " ('nastya', 54758),\n",
       " ('простить', 144269),\n",
       " ('утро', 160527)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(vec.vocabulary_.items())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x168887 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 3 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь у нас есть вектора, на которых можно обучать модели! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t1Rq60E68ica",
    "outputId": "5caa0b70-3a96-4efb-f241-93120aa9f362"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=500, random_state=42)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=42, max_iter=500)\n",
    "clf.fit(bow, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на качество классификации на тестовой выборке. Для этого выведем classification_report из модуля [sklearn.metrics](https://scikit-learn.org/stable/modules/classes.html#sklearn-metrics-metrics)\n",
    "\n",
    "В качестве целевой метрики качества будем рассматривать macro average f1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xf8gqHSD8icc",
    "outputId": "71a8da2f-d5c6-4070-b28e-d99cc7145832"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      0.73      0.74     28591\n",
      "    positive       0.73      0.74      0.74     28118\n",
      "\n",
      "    accuracy                           0.74     56709\n",
      "   macro avg       0.74      0.74      0.74     56709\n",
      "weighted avg       0.74      0.74      0.74     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MdoG6YCr8icf"
   },
   "source": [
    "Попробуем сделать то же самое для триграмм:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3GUDAWcz8icg",
    "outputId": "88bfc3b3-7eb9-4082-f500-84d75c2e3d68"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.53      0.69     51454\n",
      "    positive       0.16      0.85      0.27      5255\n",
      "\n",
      "    accuracy                           0.56     56709\n",
      "   macro avg       0.56      0.69      0.48     56709\n",
      "weighted avg       0.90      0.56      0.65     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vec = CountVectorizer(ngram_range=(3, 3))\n",
    "bow = vec.fit_transform(x_train)\n",
    "clf = LogisticRegression(random_state=42, max_iter = 300)\n",
    "clf.fit(bow, y_train)\n",
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что качество существенно хуже. Ниже мы поймем, почему это так."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4PTszK9h8ick"
   },
   "source": [
    "## TF-IDF векторизация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xQ9Td4bw8icm"
   },
   "source": [
    "`TfidfVectorizer` делает то же, что и `CountVectorizer`, но в качестве значений – tf-idf каждого слова.\n",
    "\n",
    "Как считается tf-idf:\n",
    "\n",
    "TF (term frequency) – относительная частотность слова в документе:\n",
    "$$ TF(t,d) = \\frac{n_t}{\\sum_k n_k} $$\n",
    "\n",
    "`t` -- слово (term), `d` -- документ, $n_t$ -- количество вхождений слова, $n_k$ -- количество вхождений остальных слов\n",
    "\n",
    "IDF (inverse document frequency) – обратная частота документов, в которых есть это слово:\n",
    "$$ IDF(t, D) = \\mbox{log} \\frac{|D|}{|{d : t \\in d}|} $$\n",
    "\n",
    "`t` -- слово (term), `D` -- коллекция документов\n",
    "\n",
    "Перемножаем их:\n",
    "$$TF–IDF(t,d,D) = TF(t,d) \\times IDF(i, D)$$\n",
    "\n",
    "Ключевая идея этого подхода – если слово часто встречается в одном документе, но в целом по корпусу встречается в небольшом \n",
    "количестве документов, у него высокий TF-IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q8B_Q8qP8icm"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tn-S--vi8ico",
    "outputId": "42455755-3c0c-4ab2-c08d-caf318cad0d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.70      0.74      0.72     26386\n",
      "    positive       0.76      0.72      0.74     30323\n",
      "\n",
      "    accuracy                           0.73     56709\n",
      "   macro avg       0.73      0.73      0.73     56709\n",
      "weighted avg       0.73      0.73      0.73     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vec = TfidfVectorizer(ngram_range=(1, 1))\n",
    "bow = vec.fit_transform(x_train)\n",
    "clf = LogisticRegression(random_state=42, max_iter = 500)\n",
    "clf.fit(bow, y_train)\n",
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fXglD7lb8icq"
   },
   "source": [
    "В этот раз получилось хуже, чем с помощью простого CountVectorizer, то есть использование tf-idf не дало улучшений в качестве. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ETq8X_Tb8idz"
   },
   "source": [
    "## О важности эксплоративного анализа\n",
    "\n",
    "Иногда в ходе стандартного препроцессинга теряются важные признаки. Посмотрим, что будет если не убирать пунктуацию?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>lemmas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2903</th>\n",
       "      <td>У меня за стеной у кого-то веселье. Пьяные мужские голоса поют что-то в руссконародном духе. Смешно))</td>\n",
       "      <td>positive</td>\n",
       "      <td>стена веселие пьяный мужской голос петь руссконародный смешно</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                       text     label                                                         lemmas\n",
       "2903  У меня за стеной у кого-то веселье. Пьяные мужские голоса поют что-то в руссконародном духе. Смешно))  positive  стена веселие пьяный мужской голос петь руссконародный смешно"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>lemmas</th>\n",
       "      <th>new_lemmas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16330</th>\n",
       "      <td>RT @qohavaboweka: удалить....нужно срочно удалить человек 500 из ЖЖ... как это сделать никого не обидев(((</td>\n",
       "      <td>negative</td>\n",
       "      <td>qohavaboweka удалить нужно срочно удалить человек сделать никто обидеть</td>\n",
       "      <td>rt @qohavaboweka: удалить....нужно срочно удалить человек 500 из жж... как это сделать никого не обидев(((</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83975</th>\n",
       "      <td>@nadi_yurkovets столько приятностей в один день мне еще не говорили, бро,я с гордостью скажу, что ты первая! и знай, что я тебя тоже люблю:)</td>\n",
       "      <td>positive</td>\n",
       "      <td>nadi_yurkovets столько приятность день говорить гордость сказать первый знать любить</td>\n",
       "      <td>@nadi_yurkovets столько приятностей в один день мне еще не говорили, бро,я с гордостью скажу, что ты первая! и знай, что я тебя тоже люблю:)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67219</th>\n",
       "      <td>я какая-то не такая:( изменилась может быть...</td>\n",
       "      <td>negative</td>\n",
       "      <td>измениться мочь</td>\n",
       "      <td>я какая-то не такая:( изменилась может быть...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                               text     label                                                                                lemmas                                                                                                                                    new_lemmas\n",
       "16330                                    RT @qohavaboweka: удалить....нужно срочно удалить человек 500 из ЖЖ... как это сделать никого не обидев(((  negative               qohavaboweka удалить нужно срочно удалить человек сделать никто обидеть                                    rt @qohavaboweka: удалить....нужно срочно удалить человек 500 из жж... как это сделать никого не обидев(((\n",
       "83975  @nadi_yurkovets столько приятностей в один день мне еще не говорили, бро,я с гордостью скажу, что ты первая! и знай, что я тебя тоже люблю:)  positive  nadi_yurkovets столько приятность день говорить гордость сказать первый знать любить  @nadi_yurkovets столько приятностей в один день мне еще не говорили, бро,я с гордостью скажу, что ты первая! и знай, что я тебя тоже люблю:)\n",
       "67219                                                                                                я какая-то не такая:( изменилась может быть...  negative                                                                       измениться мочь                                                                                                я какая-то не такая:( изменилась может быть..."
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['new_lemmas'] = df.text.apply(lambda x: x.lower())\n",
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df.new_lemmas, df.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ue0DUsX18id0",
    "outputId": "f3858c1f-554f-4f18-8cc4-6fa5416702ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00     27859\n",
      "    positive       1.00      1.00      1.00     28850\n",
      "\n",
      "    accuracy                           1.00     56709\n",
      "   macro avg       1.00      1.00      1.00     56709\n",
      "weighted avg       1.00      1.00      1.00     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk import word_tokenize\n",
    "\n",
    "vec = TfidfVectorizer(ngram_range=(1, 1), tokenizer=word_tokenize)\n",
    "bow = vec.fit_transform(x_train)\n",
    "clf = LogisticRegression(random_state=42, max_iter = 300)\n",
    "clf.fit(bow, y_train)\n",
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wymeD7-B8id3"
   },
   "source": [
    "Как можно видеть, если оставить пунктуацию, то все метрики равны 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(260034, 260034)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vec.vocabulary_), len(clf.coef_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DGKuAvYR8id3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('вчера', 0.2136572091594278)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances = list(zip(vec.vocabulary_, clf.coef_[0]))\n",
    "importances[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('весело', 58.44800689285947),\n",
       " ('maxnest', 26.87589763915838),\n",
       " ('metdasha', 10.474993882107558),\n",
       " ('mooney_lupin', 9.174847685759397),\n",
       " ('вкусне', 7.901848649134337),\n",
       " ('шмотки', 7.3767992135484715),\n",
       " ('ходить', 7.017478527197771),\n",
       " ('bagusbdman', 6.136608669599598),\n",
       " ('уставшая', 4.840771075371882),\n",
       " ('жизни.спасибо', 3.066545371925849)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_importances = sorted(importances, key = lambda x: -x[1])\n",
    "sorted_importances[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1QxmioaZ8id8"
   },
   "source": [
    "Посмотрим, как один из наиболее значительных токенов справится с классификацией безо всякого машинного обучения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "17LPHPGR8id9",
    "outputId": "50c87666-43d1-401e-fef9-c19d4faa5e20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.85      0.92     32878\n",
      "    positive       0.83      1.00      0.91     23831\n",
      "\n",
      "    accuracy                           0.91     56709\n",
      "   macro avg       0.91      0.92      0.91     56709\n",
      "weighted avg       0.93      0.91      0.91     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cool_token = ')'\n",
    "pred = ['positive' if cool_token in tweet else 'negative' for tweet in x_test]\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно видеть, что это уже позволяет достаточно хорошо классифицировать тексты."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B7VjSCog8id_"
   },
   "source": [
    "## Символьные n-граммы\n",
    "\n",
    "Теперь в качестве признаком используем, например, униграммы символов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZSO-k4wA8id_",
    "outputId": "29b7529b-d86c-466a-802d-186284782503"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      1.00     27799\n",
      "    positive       1.00      0.99      1.00     28910\n",
      "\n",
      "    accuracy                           1.00     56709\n",
      "   macro avg       1.00      1.00      1.00     56709\n",
      "weighted avg       1.00      1.00      1.00     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vec = CountVectorizer(analyzer='char', ngram_range=(1, 1))\n",
    "bow = vec.fit_transform(x_train)\n",
    "clf = LogisticRegression(random_state=42, max_iter=1000)\n",
    "clf.fit(bow, y_train)\n",
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9i6JwqL-8ieE"
   },
   "source": [
    "Таким образом, становится понятно, почему на этих данных качество классификации 1. Так или иначе, на символах классифицировать тоже можно.\n",
    "\n",
    "Ещё одна замечательная особенность символьных признаков: токенизация и лемматизация не нужна, можно использовать такой подход для языков, у которых нет готовых анализаторов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Итоги\n",
    "\n",
    " На этом занятии мы\n",
    "* познакомились с задачей бинарной классификации текстов.\n",
    "\n",
    "* научились строить простые признаки на основе метода \"мешка слов\" с помощью библиотеки sklearn: CountVectorizer и TfidfVectorizer.\n",
    "\n",
    "* использовали для классификации линейную модель логистической регрессии.\n",
    "\n",
    "* поняли, что многое зависит от подхода к предобработки текста и от признаков, которые используются в модели.\n",
    "\n",
    "* увидели, что в некоторых задачах важно использование каждого символа из текста, в том числе пунктуации.\n",
    "\n",
    "На следующих занятиях мы рассмотрим более сложные модели построения признаков и классификации текстов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "1_preprocessing.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
